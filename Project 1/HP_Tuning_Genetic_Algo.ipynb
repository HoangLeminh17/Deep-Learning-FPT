{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VwZT5VTMkwv",
        "outputId": "74740d0b-7b16-4763-93d2-4d11c97eb0e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generation 1: Best Val Accuracy = 0.8535, Hidden Layers = 1, Units = 32, Dropout = 0.1300, LR = 0.000992, Batch Size = 96\n",
            "Generation 2: Best Val Accuracy = 0.8546, Hidden Layers = 1, Units = 32, Dropout = 0.1302, LR = 0.003943, Batch Size = 96\n",
            "Generation 3: Best Val Accuracy = 0.8595, Hidden Layers = 1, Units = 32, Dropout = 0.1300, LR = 0.000992, Batch Size = 96\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "\n",
        "# Tải và tiền xử lý dữ liệu Fashion MNIST\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "x_train = x_train / 255.0  # Chuẩn hóa\n",
        "x_test = x_test / 255.0\n",
        "y_train = y_train.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "\n",
        "# Hàm tạo mô hình (tương tự create_model trong notebook)\n",
        "def create_model(individual):\n",
        "    num_hidden_layers, num_units, dropout_rate, learning_rate, batch_size = individual\n",
        "    num_hidden_layers = int(num_hidden_layers)\n",
        "    num_units = int(num_units)\n",
        "    batch_size = int(batch_size)\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "    for _ in range(num_hidden_layers):\n",
        "        model.add(tf.keras.layers.Dense(num_units, activation='relu'))\n",
        "        model.add(tf.keras.layers.Dropout(dropout_rate))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model, batch_size\n",
        "\n",
        "# Hàm đánh giá (fitness function)\n",
        "def evaluate_individual(individual):\n",
        "    model, batch_size = create_model(individual)\n",
        "    try:\n",
        "        model.fit(\n",
        "            x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=5,\n",
        "            validation_data=(x_test, y_test),\n",
        "            verbose=0\n",
        "        )\n",
        "        _, val_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
        "        return val_accuracy\n",
        "    except:\n",
        "        return 0.0  # Trả về fitness thấp nếu có lỗi\n",
        "\n",
        "# Khởi tạo quần thể\n",
        "def initialize_population(pop_size):\n",
        "    population = []\n",
        "    for _ in range(pop_size):\n",
        "        num_hidden_layers = random.choice([1, 2, 3])\n",
        "        num_units = random.choice([8, 16, 32])\n",
        "        dropout_rate = random.uniform(0.1, 0.5)\n",
        "        learning_rate = random.uniform(0.0001, 0.01)\n",
        "        batch_size = random.choice([32, 64, 96, 128])\n",
        "        population.append((num_hidden_layers, num_units, dropout_rate, learning_rate, batch_size))\n",
        "    return population\n",
        "\n",
        "# Lai ghép (crossover)\n",
        "def crossover(parent1, parent2):\n",
        "    w = random.random()\n",
        "    new_hidden_layers = random.choice([parent1[0], parent2[0]])\n",
        "    new_units = random.choice([parent1[1], parent2[1]])\n",
        "    new_dropout = w * parent1[2] + (1 - w) * parent2[2]\n",
        "    new_lr = w * parent1[3] + (1 - w) * parent2[3]\n",
        "    new_batch_size = random.choice([parent1[4], parent2[4]])\n",
        "    # Giới hạn giá trị\n",
        "    new_dropout = max(0.1, min(0.5, new_dropout))\n",
        "    new_lr = max(0.0001, min(0.01, new_lr))\n",
        "    return (new_hidden_layers, new_units, new_dropout, new_lr, new_batch_size)\n",
        "\n",
        "# Đột biến (mutation)\n",
        "def mutate(individual, mutation_rate=0.1):\n",
        "    num_hidden_layers, num_units, dropout_rate, learning_rate, batch_size = individual\n",
        "    if random.random() < mutation_rate:\n",
        "        num_hidden_layers = random.choice([1, 2, 3])\n",
        "    if random.random() < mutation_rate:\n",
        "        num_units = random.choice([8, 16, 32])\n",
        "    if random.random() < mutation_rate:\n",
        "        dropout_rate = dropout_rate + random.gauss(0, 0.05)\n",
        "        dropout_rate = max(0.1, min(0.5, dropout_rate))\n",
        "    if random.random() < mutation_rate:\n",
        "        learning_rate = learning_rate + random.gauss(0, 0.001)\n",
        "        learning_rate = max(0.0001, min(0.01, learning_rate))\n",
        "    if random.random() < mutation_rate:\n",
        "        batch_size = random.choice([32, 64, 96, 128])\n",
        "    return (num_hidden_layers, num_units, dropout_rate, learning_rate, batch_size)\n",
        "\n",
        "# Thuật toán di truyền\n",
        "def genetic_algorithm(pop_size=20, n_generations=10, mutation_rate=0.1, elitism=0.1):\n",
        "    population = initialize_population(pop_size)\n",
        "    best_individuals = []\n",
        "\n",
        "    for generation in range(n_generations):\n",
        "        # Đánh giá fitness\n",
        "        fitness_scores = [(ind, evaluate_individual(ind)) for ind in population]\n",
        "        fitness_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Lưu 3 cá thể tốt nhất\n",
        "        best_individuals = fitness_scores[:3]\n",
        "\n",
        "        # In thông tin thế hệ\n",
        "        best_individual, best_fitness = fitness_scores[0]\n",
        "        print(f\"Generation {generation + 1}: Best Val Accuracy = {best_fitness:.4f}, \"\n",
        "              f\"Hidden Layers = {int(best_individual[0])}, \"\n",
        "              f\"Units = {int(best_individual[1])}, \"\n",
        "              f\"Dropout = {best_individual[2]:.4f}, \"\n",
        "              f\"LR = {best_individual[3]:.6f}, \"\n",
        "              f\"Batch Size = {int(best_individual[4])}\")\n",
        "\n",
        "        # Elitism\n",
        "        n_elite = int(elitism * pop_size)\n",
        "        new_population = [ind for ind, _ in fitness_scores[:n_elite]]\n",
        "\n",
        "        # Tạo cá thể mới\n",
        "        while len(new_population) < pop_size:\n",
        "            parents = random.sample(fitness_scores[:pop_size//2], 2)\n",
        "            parent1, parent2 = parents[0][0], parents[1][0]\n",
        "            child = crossover(parent1, parent2)\n",
        "            child = mutate(child, mutation_rate)\n",
        "            new_population.append(child)\n",
        "\n",
        "        population = new_population\n",
        "\n",
        "    return best_individuals\n",
        "\n",
        "# Chạy thuật toán di truyền\n",
        "best_three = genetic_algorithm(pop_size=20, n_generations=3, mutation_rate=0.1)\n",
        "print(\"\\nThree best parameter sets found:\")\n",
        "for i, (params, accuracy) in enumerate(best_three, 1):\n",
        "    print(f\"Set {i}: Val Accuracy = {accuracy:.4f}, \"\n",
        "          f\"Hidden Layers = {int(params[0])}, \"\n",
        "          f\"Units = {int(params[1])}, \"\n",
        "          f\"Dropout = {params[2]:.4f}, \"\n",
        "          f\"Learning Rate = {params[3]:.6f}, \"\n",
        "          f\"Batch Size = {int(params[4])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dfw0jBX7Pr84",
        "outputId": "a2468558-2b36-480a-abf9-7bd6824ac41d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generation 1: Best Val Accuracy = 0.8848, Hidden Layers = 2, Units = 64, Dropout = 0.1064, LR = 0.001531, Batch Size = 64\n",
            "Generation 2: Best Val Accuracy = 0.8832, Hidden Layers = 2, Units = 256, Dropout = 0.1109, LR = 0.000858, Batch Size = 256\n",
            "Generation 3: Best Val Accuracy = 0.8863, Hidden Layers = 2, Units = 256, Dropout = 0.1109, LR = 0.000858, Batch Size = 256\n",
            "Generation 4: Best Val Accuracy = 0.8863, Hidden Layers = 2, Units = 256, Dropout = 0.1109, LR = 0.000858, Batch Size = 256\n",
            "Generation 5: Best Val Accuracy = 0.8812, Hidden Layers = 2, Units = 256, Dropout = 0.2242, LR = 0.003323, Batch Size = 64\n",
            "\n",
            "Three best parameter sets found (based on validation accuracy):\n",
            "Set 1: Val Accuracy = 0.8812, Hidden Layers = 2, Units = 256, Dropout = 0.2242, Learning Rate = 0.003323, Batch Size = 64\n",
            "Set 2: Val Accuracy = 0.8802, Hidden Layers = 2, Units = 256, Dropout = 0.2179, Learning Rate = 0.003079, Batch Size = 256\n",
            "Set 3: Val Accuracy = 0.8800, Hidden Layers = 2, Units = 256, Dropout = 0.1465, Learning Rate = 0.003602, Batch Size = 64\n",
            "Epoch 1/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7644 - loss: 0.6712 - val_accuracy: 0.8314 - val_loss: 0.4814\n",
            "Epoch 2/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8372 - loss: 0.4472 - val_accuracy: 0.8441 - val_loss: 0.4361\n",
            "Epoch 3/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8486 - loss: 0.4151 - val_accuracy: 0.8568 - val_loss: 0.3948\n",
            "Epoch 4/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8567 - loss: 0.3971 - val_accuracy: 0.8598 - val_loss: 0.3800\n",
            "Epoch 5/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8592 - loss: 0.3806 - val_accuracy: 0.8610 - val_loss: 0.3773\n",
            "Epoch 6/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8662 - loss: 0.3653 - val_accuracy: 0.8675 - val_loss: 0.3550\n",
            "Epoch 7/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8696 - loss: 0.3600 - val_accuracy: 0.8727 - val_loss: 0.3462\n",
            "Epoch 8/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8707 - loss: 0.3552 - val_accuracy: 0.8746 - val_loss: 0.3427\n",
            "Epoch 9/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.3489 - val_accuracy: 0.8737 - val_loss: 0.3443\n",
            "Epoch 10/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8744 - loss: 0.3423 - val_accuracy: 0.8722 - val_loss: 0.3491\n",
            "Epoch 11/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8779 - loss: 0.3296 - val_accuracy: 0.8748 - val_loss: 0.3614\n",
            "Epoch 12/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8818 - loss: 0.3269 - val_accuracy: 0.8637 - val_loss: 0.3763\n",
            "Epoch 13/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8795 - loss: 0.3218 - val_accuracy: 0.8660 - val_loss: 0.3671\n",
            "Epoch 14/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8828 - loss: 0.3138 - val_accuracy: 0.8756 - val_loss: 0.3463\n",
            "Epoch 15/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8863 - loss: 0.3108 - val_accuracy: 0.8760 - val_loss: 0.3439\n",
            "Epoch 16/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8847 - loss: 0.3111 - val_accuracy: 0.8821 - val_loss: 0.3286\n",
            "Epoch 17/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8870 - loss: 0.3039 - val_accuracy: 0.8733 - val_loss: 0.3494\n",
            "Epoch 18/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8887 - loss: 0.3013 - val_accuracy: 0.8713 - val_loss: 0.3465\n",
            "Epoch 19/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8872 - loss: 0.3039 - val_accuracy: 0.8817 - val_loss: 0.3229\n",
            "\n",
            "Final Test Accuracy with best parameters: 0.8758\n"
          ]
        }
      ],
      "source": [
        "# Bản cải tiến cho accuracy cao nhất (maybe?)\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Tải và tiền xử lý dữ liệu Fashion MNIST\n",
        "(x_train_full, y_train_full), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "x_train_full = x_train_full / 255.0\n",
        "x_test = x_test / 255.0\n",
        "y_train_full = y_train_full.astype(np.int32)\n",
        "y_test = y_test.astype(np.int32)\n",
        "\n",
        "# Chia tập train thành train và validation (80/20)\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.2, random_state=42)\n",
        "\n",
        "# Hàm tạo mô hình\n",
        "def create_model(individual):\n",
        "    num_hidden_layers, num_units, dropout_rate, learning_rate, batch_size = individual\n",
        "    num_hidden_layers = int(num_hidden_layers)\n",
        "    num_units = int(num_units)\n",
        "    batch_size = int(batch_size)\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
        "\n",
        "    for _ in range(num_hidden_layers):\n",
        "        model.add(tf.keras.layers.Dense(num_units, activation='relu'))\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Dropout(dropout_rate))\n",
        "\n",
        "    model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "    return model, batch_size\n",
        "\n",
        "# Hàm đánh giá (fitness function)\n",
        "def evaluate_individual(individual):\n",
        "    model, batch_size = create_model(individual)\n",
        "    try:\n",
        "        model.fit(\n",
        "            x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=10,\n",
        "            validation_data=(x_val, y_val),\n",
        "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)],\n",
        "            verbose=0\n",
        "        )\n",
        "        _, val_accuracy = model.evaluate(x_val, y_val, verbose=0)\n",
        "        return val_accuracy\n",
        "    except:\n",
        "        return 0.0\n",
        "\n",
        "# Khởi tạo quần thể\n",
        "def initialize_population(pop_size):\n",
        "    population = []\n",
        "    for _ in range(pop_size):\n",
        "        num_hidden_layers = random.choice([1, 2, 3, 4])\n",
        "        num_units = random.choice([32, 64, 128, 256])\n",
        "        dropout_rate = random.uniform(0.1, 0.3)\n",
        "        learning_rate = random.uniform(0.0001, 0.01)\n",
        "        batch_size = random.choice([32, 64, 128, 256])\n",
        "        population.append((num_hidden_layers, num_units, dropout_rate, learning_rate, batch_size))\n",
        "    return population\n",
        "\n",
        "# Lai ghép (crossover)\n",
        "def crossover(parent1, parent2):\n",
        "    w = random.random()\n",
        "    new_hidden_layers = random.choice([parent1[0], parent2[0]])\n",
        "    new_units = random.choice([parent1[1], parent2[1]])\n",
        "    new_dropout = w * parent1[2] + (1 - w) * parent2[2]\n",
        "    new_lr = w * parent1[3] + (1 - w) * parent2[3]\n",
        "    new_batch_size = random.choice([parent1[4], parent2[4]])\n",
        "    new_dropout = max(0.1, min(0.3, new_dropout))\n",
        "    new_lr = max(0.0001, min(0.01, new_lr))\n",
        "    return (new_hidden_layers, new_units, new_dropout, new_lr, new_batch_size)\n",
        "\n",
        "# Đột biến (mutation)\n",
        "def mutate(individual, mutation_rate=0.1):\n",
        "    num_hidden_layers, num_units, dropout_rate, learning_rate, batch_size = individual\n",
        "    if random.random() < mutation_rate:\n",
        "        num_hidden_layers = random.choice([1, 2, 3, 4])\n",
        "    if random.random() < mutation_rate:\n",
        "        num_units = random.choice([32, 64, 128, 256])\n",
        "    if random.random() < mutation_rate:\n",
        "        dropout_rate = dropout_rate + random.gauss(0, 0.05)\n",
        "        dropout_rate = max(0.1, min(0.3, dropout_rate))\n",
        "    if random.random() < mutation_rate:\n",
        "        learning_rate = learning_rate + random.gauss(0, 0.001)\n",
        "        learning_rate = max(0.0001, min(0.01, learning_rate))\n",
        "    if random.random() < mutation_rate:\n",
        "        batch_size = random.choice([32, 64, 128, 256])\n",
        "    return (num_hidden_layers, num_units, dropout_rate, learning_rate, batch_size)\n",
        "\n",
        "# Thuật toán di truyền\n",
        "def genetic_algorithm(pop_size=30, n_generations=15, mutation_rate=0.1, elitism=0.1):\n",
        "    population = initialize_population(pop_size)\n",
        "    best_individuals = []\n",
        "\n",
        "    for generation in range(n_generations):\n",
        "        fitness_scores = [(ind, evaluate_individual(ind)) for ind in population]\n",
        "        fitness_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        best_individuals = fitness_scores[:3]\n",
        "\n",
        "        best_individual, best_fitness = fitness_scores[0]\n",
        "        print(f\"Generation {generation + 1}: Best Val Accuracy = {best_fitness:.4f}, \"\n",
        "              f\"Hidden Layers = {int(best_individual[0])}, \"\n",
        "              f\"Units = {int(best_individual[1])}, \"\n",
        "              f\"Dropout = {best_individual[2]:.4f}, \"\n",
        "              f\"LR = {best_individual[3]:.6f}, \"\n",
        "              f\"Batch Size = {int(best_individual[4])}\")\n",
        "\n",
        "        n_elite = int(elitism * pop_size)\n",
        "        new_population = [ind for ind, _ in fitness_scores[:n_elite]]\n",
        "\n",
        "        while len(new_population) < pop_size:\n",
        "            parents = random.sample(fitness_scores[:pop_size//2], 2)\n",
        "            parent1, parent2 = parents[0][0], parents[1][0]\n",
        "            child = crossover(parent1, parent2)\n",
        "            child = mutate(child, mutation_rate)\n",
        "            new_population.append(child)\n",
        "\n",
        "        population = new_population\n",
        "\n",
        "    return best_individuals\n",
        "\n",
        "# Chạy thuật toán di truyền\n",
        "best_three = genetic_algorithm(pop_size=30, n_generations=5, mutation_rate=0.1)\n",
        "\n",
        "# In 3 bộ siêu tham số tốt nhất\n",
        "print(\"\\nThree best parameter sets found (based on validation accuracy):\")\n",
        "for i, (params, accuracy) in enumerate(best_three, 1):\n",
        "    print(f\"Set {i}: Val Accuracy = {accuracy:.4f}, \"\n",
        "          f\"Hidden Layers = {int(params[0])}, \"\n",
        "          f\"Units = {int(params[1])}, \"\n",
        "          f\"Dropout = {params[2]:.4f}, \"\n",
        "          f\"Learning Rate = {params[3]:.6f}, \"\n",
        "          f\"Batch Size = {int(params[4])}\")\n",
        "\n",
        "# Đánh giá lại mô hình tốt nhất trên tập test\n",
        "best_params = best_three[0][0]\n",
        "model, batch_size = create_model(best_params)\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=20,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3)],\n",
        "    verbose=1\n",
        ")\n",
        "_, test_accuracy = model.evaluate(x_test, y_test, verbose=0) # model.get_weights() để lấy các tham số\n",
        "print(f\"\\nFinal Test Accuracy with best parameters: {test_accuracy:.4f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
